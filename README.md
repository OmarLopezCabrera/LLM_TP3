
# ğŸ§  Chatbot Modular de Razonamiento Avanzado (TP3 - LLMs y Agentes)

Este proyecto implementa un **sistema de respuesta inteligente y razonamiento complejo** basado en un flujo modular de **6 agentes especializados**.  
Cada agente cumple una funciÃ³n distinta en el procesamiento de la pregunta, generando una respuesta robusta y revisada.

---

## ğŸ“‹ DescripciÃ³n general

- **RecepciÃ³n de preguntas complejas:** El sistema recibe consultas que requieren bÃºsqueda, anÃ¡lisis, soluciones y referencias.
- **Agentes especializados:** Se activan 6 agentes consecutivos para explorar, planificar, resolver, buscar informaciÃ³n, sintetizar y revisar.
- **EstimaciÃ³n de tokens:** Mide el uso de tokens de entrada, salida, razonamiento y total (de forma estimada si no hay reporte real).
- **Resultados estructurados:** Muestra tanto la respuesta final como el detalle intermedio de cada etapa del razonamiento.

---

## ğŸ—ï¸ Estructura del proyecto

| Archivo                  | DescripciÃ³n |
|:--------------------------|:------------|
| `agent_module.py`         | LÃ³gica de los 6 agentes y orquestaciÃ³n del flujo. |
| `razonamiento_app.py`     | AplicaciÃ³n Streamlit para interactuar con el chatbot. |
| `requirements.txt`        | Dependencias necesarias para ejecutar el proyecto. |
| `README.md`               | Este archivo. |

---

## ğŸ¤– Flujo de agentes

El sistema sigue el siguiente flujo modular:

1. **Explorador:** Analiza el contexto general de la pregunta.
2. **Estratega:** Propone mÃ©todos o enfoques de soluciÃ³n.
3. **Solucionador:** Busca soluciones concretas basadas en los enfoques.
4. **Investigador Web:** Nombra artÃ­culos, autores y referencias relevantes.
5. **Arquitecto:** Sintetiza toda la informaciÃ³n en una respuesta estructurada.
6. **Revisor:** Revisa, refina y sugiere mejoras a la respuesta final.

---

## ğŸ”§ Requisitos

### Software
- **Python 3.9 o superior**
- **Streamlit** para la interfaz grÃ¡fica.
- **LangChain** como framework de orquestaciÃ³n de agentes.
- **Groq API** como proveedor de LLMs (Llama 3 70B 8192).

### InstalaciÃ³n de bibliotecas

Instalar todas las dependencias ejecutando:

```bash
pip install -r requirements.txt
```

### Variables de entorno

Debes configurar las siguientes variables de entorno:

```bash
GROQ_API_KEY = "tu_api_key_de_groq"
GROQ_MODEL = "llama3-70b-8192"  # opcional
```

---

## ğŸš€ EjecuciÃ³n

1. Ejecutar la aplicaciÃ³n Streamlit:

```bash
streamlit run razonamiento_app.py
```

2. Escribir preguntas como:
   - "Â¿CuÃ¡nta energÃ­a consumen los grandes modelos LLM y quÃ© impacto ambiental tendrÃ¡n en el futuro?"
   - "Â¿QuÃ© superficie serÃ­a necesaria para abastecer el mundo con energÃ­a solar?"

El sistema responderÃ¡ utilizando el razonamiento de los 6 agentes.

---

## ğŸ“š TecnologÃ­as utilizadas

- [Streamlit](https://streamlit.io/)
- [LangChain](https://python.langchain.com/)
- [Groq API](https://groq.com/)

---

## ğŸ‘¨â€ğŸ’» Autor

Trabajo realizado por **Omar LÃ³pez Cabrera** 

---
